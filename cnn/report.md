# 機械学習(CNN) 3I44 吉髙僚眞

## 1. 目的
1. 機械学習とはどのようなものがあるかを知る。
2. PyTorchモジュールにあるNN(ニューラルネットワーク)を使用して入力データが何に属するかのクラスを分類する。
3. サンプルを実行してみて機械学習を体感してみる。
4. データセットの変更＋CNNの構造・設定を理解して分類クラスを増加させてみる。
5. 設定を調整して、出力されるデータの変化を確認し、設定の重要性を知る。

## 実験1: CIFAR10データセットを使用した学習

### 2.サンプルコードに設定されているCNNの規模(何層がどのくらいの大きさで何層あるか)

```python
def __init__(self):
         super().__init__()
         self.conv1 = nn.Conv2d(3, 6, 5) # 1 畳み込み層1　入力チャネル数:3 出力チャネル数:6 カーネルサイズ:5
         self.pool = nn.MaxPool2d(2, 2)  # 2,4 プーリング層　カーネルサイズ:2x2
         self.conv2 = nn.Conv2d(6, 16, 5)  # 3 畳み込み層2
         self.fc1 = nn.Linear(16 * 5 * 5, 120)　# 5 全結合層　画像は5x5のピクセル フィルター数:16 出力ベクトル数:120
         self.fc2 = nn.Linear(120, 84) # 6 全結合層 入力サイズ:120 出力サイズ:84
         self.fc3 = nn.Linear(84, 10) # 7 出力は10個
```

CNNの設定は以上のとおりである。以下のような処理を行っている。
1. 1つ目の畳み込み層で32x32の画像をRGBの3チャネルで入力を行い6つのフィルタを使って6チャネルの特徴に分けて出力する。カーネルサイズの5x5ずつ見ていき出力されるのは28x28のデータになる。
2. プーリング層で28x28の画像を2x2ずつ1ドットずつずらして見ていき14x14にする。
3. 2つ目の畳み込み層では先ほどの結果より6チャネルで入力を行いフィルタをかけて16チャネルで出力する。カーネルサイズ5x5ずつ見ていき出力は10x10になる。
4. もう一度プーリング層で10x10の画像を2x2ずつ1ドットずつずらして見ていき5x5にする。
5. 1つ目の全結合層では先ほどまでで出力された5x5のピクセル画像を入力する。そのため、入力特徴量には16x5x5を入れる。出力ベクトル数は120で出力する。
6. 2つ目の全結合層では、先ほどの結果の120個のニューロンを入力して、から84個のニューロンを出力する
7. 4つ目の全結合層では、先ほどの結果の84個を入力して10個の出力にする。

### 3.CIFAR10データを使用した機械学習の実行結果のキャプチャ(コピペでも可)

```bash
100%|██████████| 170M/170M [00:02<00:00, 74.5MB/s]
学習進捗：[学習回数：1, ミニバッチ数： 1000] loss: 2.283
学習進捗：[学習回数：1, ミニバッチ数： 2000] loss: 2.042
学習進捗：[学習回数：1, ミニバッチ数： 3000] loss: 1.871
学習進捗：[学習回数：1, ミニバッチ数： 4000] loss: 1.752
学習進捗：[学習回数：1, ミニバッチ数： 5000] loss: 1.692
学習進捗：[学習回数：1, ミニバッチ数： 6000] loss: 1.627
学習進捗：[学習回数：1, ミニバッチ数： 7000] loss: 1.596
学習進捗：[学習回数：1, ミニバッチ数： 8000] loss: 1.536
学習進捗：[学習回数：1, ミニバッチ数： 9000] loss: 1.526
学習進捗：[学習回数：1, ミニバッチ数：10000] loss: 1.485
学習進捗：[学習回数：1, ミニバッチ数：11000] loss: 1.461
学習進捗：[学習回数：1, ミニバッチ数：12000] loss: 1.451
-----学習完了-----
```

## 実験2: 学習モデルによる分類(CIFAR10)

### 4.使用したサンプル画像
<img src="deer.png">

手元にあった鹿の画像

### 5.サンプル画像を入力して計算されたスコアのキャプチャ(コピペでも可)

```
tensor([0.0495, 0.0078, 0.2211, 0.1560, 0.1672, 0.1991, 0.0621, 0.1020, 0.0159,
        0.0192], grad_fn=<SoftmaxBackward0>)
```

| 分類 | 確率   |
| ---- | ------ |
| bird | 0.2211 |
| dog  | 0.1991 |
| deer | 0.1672 |
| cat  | 0.1560 |

確率が高い順に書くと、birdが22%となり、正しい結果であるdeerは16%となって3番目であった。

## 実験3: データセットの変更と規模の拡大

### 6.CIFAR100データを使用した機械学習の実行結果のキャプチャ(コピペでも可)
```bash
学習進捗：[学習回数：1, ミニバッチ数： 1000] loss: 4.605
学習進捗：[学習回数：1, ミニバッチ数： 2000] loss: 4.603
学習進捗：[学習回数：1, ミニバッチ数： 3000] loss: 4.584
学習進捗：[学習回数：1, ミニバッチ数： 4000] loss: 4.477
学習進捗：[学習回数：1, ミニバッチ数： 5000] loss: 4.266
学習進捗：[学習回数：1, ミニバッチ数： 6000] loss: 4.088
学習進捗：[学習回数：1, ミニバッチ数： 7000] loss: 4.076
学習進捗：[学習回数：1, ミニバッチ数： 8000] loss: 4.025
学習進捗：[学習回数：1, ミニバッチ数： 9000] loss: 3.948
学習進捗：[学習回数：1, ミニバッチ数：10000] loss: 3.874
学習進捗：[学習回数：1, ミニバッチ数：11000] loss: 3.858
学習進捗：[学習回数：1, ミニバッチ数：12000] loss: 3.817
-----学習完了-----
```


### 7.CIFAR100に対応する為に変更したCNNの設定(何層がどのくらいの大きさで何層あるか)

```python
class CNN(nn.Module):
    def __init__(self):
         super().__init__()
         self.conv1 = nn.Conv2d(3, 6, 5) # 1 畳み込み層1　入力チャネル数:3 出力チャネル数:6 カーネルサイズ:5
         self.pool = nn.MaxPool2d(2, 2) # 2 プーリング層　カーネルサイズ:2x2
         self.conv2 = nn.Conv2d(6, 16, 5) # 3 畳み込み層2
         self.fc1 = nn.Linear(16 * 5 * 5, 240) # 4 全結合層　画像は5x5のピクセル フィルター数:16 出力ベクトル数:240
         self.fc2 = nn.Linear(240, 180) # 5 全結合層 入力サイズ:240 出力サイズ:180
         self.fc3 = nn.Linear(180, 100) # 6 出力は100個
```

### 8.7で設定した内容の根拠・理由
最後の出力数(6で設定する2つ目の引数)は100にする必要があり、各層では出力数が徐々に減っていく必要があるので、それに合わせて各層も徐々に減っていくように変更した。

## 実験4:学習モデルによる分類(CIFAR100)

### 9.使用したサンプル画像

<img src="dolphin.jpg">

Wikipedia イルカ
URL: https://ja.wikipedia.org/wiki/%E3%82%A4%E3%83%AB%E3%82%AB

### 10.CIFAR100に対応させるためにテスト用プログラムを編集する。

**変更箇所抜粋**
```python
class CNN(nn.Module):
    def __init__(self):
         super().__init__()
         self.conv1 = nn.Conv2d(3, 6, 5) # 1 畳み込み層1　入力チャネル数:3 出力チャネル数:6 カーネルサイズ:5
         self.pool = nn.MaxPool2d(2, 2) # 2 プーリング層　カーネルサイズ:2x2
         self.conv2 = nn.Conv2d(6, 16, 5) # 3 畳み込み層2
         self.fc1 = nn.Linear(16 * 5 * 5, 240) # 4 全結合層　画像は5x5のピクセル フィルター数:16 出力ベクトル数:240
         self.fc2 = nn.Linear(240, 180) # 5 全結合層 入力サイズ:240 出力サイズ:180
         self.fc3 = nn.Linear(180, 100) # 6 出力は100個
#省略

def main():
# 省略
    #class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
    class_names = [ 'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle',
                        'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel',
                        'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock',
                        'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',
                        'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster',
                        'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',
                        'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',
                        'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',
                        'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',
                        'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',
                        'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',
                        'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',
                        'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',
                        'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',
                        'worm'
                        ]
# 省略
    class_corrent = list(0. for i in range(100))
    class_total = list(0. for i in range(100))
```
* クラスの定義を7で設定したものに変更した。
* 100個まで分類結果を出力するためにrangeの引数を100に変更した。

### 11.実験2で使用した画像を使用して、分類を行ってみる。
```
tensor([0.0005, 0.0076, 0.0022, 0.0117, 0.0092, 0.0044, 0.0018, 0.0047, 0.0071,
        0.0050, 0.0074, 0.0046, 0.0116, 0.0150, 0.0046, 0.0022, 0.0071, 0.0054,
        0.0062, 0.0040, 0.0012, 0.0156, 0.0068, 0.0056, 0.0015, 0.0124, 0.0039,
        0.0131, 0.0091, 0.0038, 0.0435, 0.0066, 0.0137, 0.0066, 0.0021, 0.0013,
        0.0008, 0.0057, 0.0023, 0.0120, 0.0151, 0.0028, 0.0109, 0.0008, 0.0036,
        0.0098, 0.0074, 0.0192, 0.0095, 0.0113, 0.0041, 0.0015, 0.0201, 0.0003,
        0.0009, 0.0138, 0.0653, 0.0013, 0.0162, 0.0363, 0.0013, 0.0036, 0.0007,
        0.0068, 0.0064, 0.0054, 0.0102, 0.0225, 0.0055, 0.0143, 0.0009, 0.0063,
        0.0285, 0.0253, 0.0047, 0.0054, 0.0599, 0.0020, 0.0072, 0.0067, 0.0066,
        0.0134, 0.0008, 0.0019, 0.0026, 0.0126, 0.0196, 0.0261, 0.0010, 0.0057,
        0.0112, 0.0060, 0.0007, 0.0315, 0.0033, 0.0518, 0.0149, 0.0070, 0.0033,
        0.0165], grad_fn=<SoftmaxBackward0>)

```

子の出力を見るとmanが6.5%, poppyが5.9%と高くなっていて、dolphinが0.08%だった。

## 実験5:チューニング
### 12. 調整したCNNモデルの学習スコア(lossの数値)のキャプチャ数枚(コピペでも可)※7より向上している事、かつ複数回である事

**1回目**

変更箇所
```py
    self.fc1 = nn.Linear(16 * 5 * 5, 800)
    self.fc2 = nn.Linear(800, 400)
    self.fc3 = nn.Linear(400, 100) 
```

実行結果

```
学習進捗：[学習回数：1, ミニバッチ数： 1000] loss: 4.604
学習進捗：[学習回数：1, ミニバッチ数： 2000] loss: 4.597
学習進捗：[学習回数：1, ミニバッチ数： 3000] loss: 4.449
学習進捗：[学習回数：1, ミニバッチ数： 4000] loss: 4.219
学習進捗：[学習回数：1, ミニバッチ数： 5000] loss: 4.120
学習進捗：[学習回数：1, ミニバッチ数： 6000] loss: 4.030
学習進捗：[学習回数：1, ミニバッチ数： 7000] loss: 3.962
学習進捗：[学習回数：1, ミニバッチ数： 8000] loss: 3.842
学習進捗：[学習回数：1, ミニバッチ数： 9000] loss: 3.845
学習進捗：[学習回数：1, ミニバッチ数：10000] loss: 3.790
学習進捗：[学習回数：1, ミニバッチ数：11000] loss: 3.734
学習進捗：[学習回数：1, ミニバッチ数：12000] loss: 3.664
-----学習完了-----
```

**2回目**

変更箇所
```py
    self.fc1 = nn.Linear(16 * 5 * 5, 1200)
    self.fc2 = nn.Linear(1200, 800)
    self.fc3 = nn.Linear(800, 100) 
```

実行結果

```
学習進捗：[学習回数：1, ミニバッチ数： 1000] loss: 4.602
学習進捗：[学習回数：1, ミニバッチ数： 2000] loss: 4.532
学習進捗：[学習回数：1, ミニバッチ数： 3000] loss: 4.327
学習進捗：[学習回数：1, ミニバッチ数： 4000] loss: 4.158
学習進捗：[学習回数：1, ミニバッチ数： 5000] loss: 4.049
学習進捗：[学習回数：1, ミニバッチ数： 6000] loss: 3.943
学習進捗：[学習回数：1, ミニバッチ数： 7000] loss: 3.904
学習進捗：[学習回数：1, ミニバッチ数： 8000] loss: 3.827
学習進捗：[学習回数：1, ミニバッチ数： 9000] loss: 3.784
学習進捗：[学習回数：1, ミニバッチ数：10000] loss: 3.712
学習進捗：[学習回数：1, ミニバッチ数：11000] loss: 3.655
学習進捗：[学習回数：1, ミニバッチ数：12000] loss: 3.603
-----学習完了-----
```

**3回目**
変更箇所
```py

MAX_EPOCH = 2
```

実行結果

```
学習進捗：[学習回数：1, ミニバッチ数： 1000] loss: 4.600
学習進捗：[学習回数：1, ミニバッチ数： 2000] loss: 4.536
学習進捗：[学習回数：1, ミニバッチ数： 3000] loss: 4.375
学習進捗：[学習回数：1, ミニバッチ数： 4000] loss: 4.257
学習進捗：[学習回数：1, ミニバッチ数： 5000] loss: 4.117
学習進捗：[学習回数：1, ミニバッチ数： 6000] loss: 4.030
学習進捗：[学習回数：1, ミニバッチ数： 7000] loss: 3.970
学習進捗：[学習回数：1, ミニバッチ数： 8000] loss: 3.856
学習進捗：[学習回数：1, ミニバッチ数： 9000] loss: 3.792
学習進捗：[学習回数：1, ミニバッチ数：10000] loss: 3.723
学習進捗：[学習回数：1, ミニバッチ数：11000] loss: 3.666
学習進捗：[学習回数：1, ミニバッチ数：12000] loss: 3.588
学習進捗：[学習回数：2, ミニバッチ数： 1000] loss: 3.491
学習進捗：[学習回数：2, ミニバッチ数： 2000] loss: 3.477
学習進捗：[学習回数：2, ミニバッチ数： 3000] loss: 3.445
学習進捗：[学習回数：2, ミニバッチ数： 4000] loss: 3.418
学習進捗：[学習回数：2, ミニバッチ数： 5000] loss: 3.379
学習進捗：[学習回数：2, ミニバッチ数： 6000] loss: 3.419
学習進捗：[学習回数：2, ミニバッチ数： 7000] loss: 3.389
学習進捗：[学習回数：2, ミニバッチ数： 8000] loss: 3.297
学習進捗：[学習回数：2, ミニバッチ数： 9000] loss: 3.310
学習進捗：[学習回数：2, ミニバッチ数：10000] loss: 3.287
学習進捗：[学習回数：2, ミニバッチ数：11000] loss: 3.272
学習進捗：[学習回数：2, ミニバッチ数：12000] loss: 3.240
-----学習完了-----
```

### 13. 実験で考えさせられた事、12が完了したと決めた要素・理由

実12の3回目では全体としてはlossは下がっているが、一部でlossが上がって、下がってという繰り返しをはじめたのでそろそろ頭打ちになりそうで6分ほど処理にかかるようになってきたので、完了したと考える。